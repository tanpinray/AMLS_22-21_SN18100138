{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad4d4f0-b107-442b-a0ac-7881dd54a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import canny\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63cda3e0-0415-47cc-a990-c7bd37ceb9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name             label\n",
       "0  IMAGE_0000.jpg  meningioma_tumor\n",
       "1  IMAGE_0001.jpg          no_tumor\n",
       "2  IMAGE_0002.jpg  meningioma_tumor\n",
       "3  IMAGE_0003.jpg      glioma_tumor\n",
       "4  IMAGE_0004.jpg  meningioma_tumor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/label.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1fa13bd-3a53-40f4-8179-0d32b126a11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['meningioma_tumor', 'no_tumor', 'glioma_tumor', 'pituitary_tumor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba7f9462-82ac-4de2-96b4-90d430ae0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classes(df):\n",
    "    '''\n",
    "    Inputs\n",
    "        df: Label data.\n",
    "        \n",
    "    Return\n",
    "        classes: List of labels - 0 if no_tumor, 1 if glioma_tumor, 2 if meningioma_tumor, 3 if pituitary_tumor\n",
    "    '''\n",
    "    \n",
    "    classes = []\n",
    "    for label in df['label']:\n",
    "        if 'no_tumor' in label:\n",
    "            classes.append(0)\n",
    "        elif 'glioma_tumor' in label:\n",
    "            classes.append(1)\n",
    "        elif 'meningioma_tumor' in label:\n",
    "            classes.append(2)\n",
    "        elif 'pituitary_tumor' in label:\n",
    "            classes.append(3)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77b709bc-3a5a-42cf-ac0c-83115c3dbf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog(data_path, df):\n",
    "    '''\n",
    "    Inputs\n",
    "        data_path: Directory path to images in dataset;\n",
    "        df: Label data.\n",
    "        \n",
    "    Return\n",
    "       hog_features: A list of HOG features for each image\n",
    "    '''\n",
    "    hog_features = []\n",
    "    for filename in df['file_name']:\n",
    "        # use imread to load image from specified file name in grayscale\n",
    "        im = imread(os.path.join(data_path, filename), as_gray = True)\n",
    "        # use resize the image to a 128 by 64 pixel image\n",
    "        resized_im = resize(im, (128, 64))\n",
    "        # Extract Histogram of Oriented Gradients (HOG) for the image\n",
    "        fd = hog(resized_im, orientations = 9, pixels_per_cell = (8, 8),\n",
    "                            cells_per_block = (2, 2), visualize = False, block_norm='L2-Hys')\n",
    "        hog_features.append(fd)\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d797c4ed-8753-4c0a-8dac-aea457b089f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp(data_path, df, numPoints, radius):\n",
    "    '''\n",
    "    Inputs\n",
    "        data_path: Directory path to images in dataset;\n",
    "        df: Label data.\n",
    "        \n",
    "    Return\n",
    "       lbp_features: A list of Local Binary Pattern (LBP) features for each image\n",
    "    '''\n",
    "    lbp_features = []\n",
    "    for filename in df['file_name']:\n",
    "        # use imread to load image from specified file name in grayscale\n",
    "        im = imread(os.path.join(data_path, filename), as_gray = True)\n",
    "        # use resize the image to a 128 by 64 pixel image\n",
    "        resized_im = resize(im, (128, 64))\n",
    "        \n",
    "        # Extract Local Binary Pattern (LBP) for the image\n",
    "        lbp = local_binary_pattern(resized_im, numPoints, radius, method=\"uniform\")\n",
    "        # Create bins for histogram\n",
    "        n_bins = int(lbp.max() + 1)\n",
    "        # Create histogram for image\n",
    "        (hist, _) = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "        \n",
    "        # # normalize the histogram\n",
    "        # hist = hist.astype(\"float\")\n",
    "        # hist /= (hist.sum() + eps)\n",
    "        \n",
    "        lbp_features.append(hist)\n",
    "    return lbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d77c13a7-0b5b-4c6a-8da8-e199e3ceec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_canny(data_path, df, sigma):\n",
    "    '''\n",
    "    Inputs\n",
    "        data_path: Directory path to images in dataset;\n",
    "        df: Label data.\n",
    "        \n",
    "    Return\n",
    "       canny_features: A list of Local Binary Pattern (LBP) features for each image\n",
    "    '''\n",
    "    canny_features = []\n",
    "    for filename in df['file_name']:\n",
    "        # use imread to load image from specified file name in grayscale\n",
    "        im = imread(os.path.join(data_path, filename), as_gray = True)\n",
    "        # use resize the image to a 128 by 64 pixel image\n",
    "        resized_im = resize(im, (128, 64))\n",
    "        \n",
    "        # Compute the Canny filter for the image\n",
    "        filtered_im = canny(resized_im, sigma=sigma)\n",
    "        filtered_im = filtered_im.ravel()\n",
    "        \n",
    "        canny_features.append(filtered_im)\n",
    "    return canny_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26814d18-7228-4bb9-9222-dbc957521ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCAPredict(X_train, X_test, k):\n",
    "    '''\n",
    "    Inputs\n",
    "        X_train: Training dataset;\n",
    "        X_test: Testing dataset;\n",
    "        k: Number of components to use.\n",
    "        \n",
    "    Return\n",
    "        X_train_PCA: Training dataset after applying PCA to reduce its dimensions;\n",
    "        X_test_PCA: Test dataset after applying PCA to reduce its dimensions.\n",
    "    '''\n",
    "\n",
    "    # the built-in function for PCA\n",
    "    pca = PCA(k)\n",
    "    \n",
    "    # the built-in function to standardize features by removing the mean and scaling to unit variance\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # fit the algorithm with dataset\n",
    "    \n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    pca.fit(X_train_scaled)\n",
    "    X_train_PCA = pca.transform(X_train_scaled)\n",
    "    X_test_PCA = pca.transform(X_test_scaled)\n",
    "    \n",
    "    # pca.fit(X_train)\n",
    "    # X_train_PCA = pca.transform(X_train)\n",
    "    # X_test_PCA = pca.transform(X_test)\n",
    "    \n",
    "    return X_train_PCA, X_test_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fffb74f1-277a-447f-9dee-0390c8903090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file for Task B with HOG features data already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./dataset/label_taskB_hog.csv'):\n",
    "    print('The csv file for Task B with HOG features data already exists')\n",
    "else:\n",
    "    data_path = './dataset/image'\n",
    "    classes = create_classes(df)\n",
    "    hog_features = extract_hog(data_path, df)\n",
    "    \n",
    "    label_taskB = pd.DataFrame(data = hog_features)\n",
    "    label_taskB['num_label'] = classes\n",
    "    label_taskB.to_csv(\"./dataset/label_taskB_hog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b87adda1-d9f5-4536-9add-62acce6b4107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file for Task B with lbp features data already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./dataset/label_taskB_lbp.csv'):\n",
    "    print('The csv file for Task B with lbp features data already exists')\n",
    "else:\n",
    "    data_path = './dataset/image'\n",
    "    classes = create_classes(df)\n",
    "    lbp_features = extract_lbp(data_path, df, 24, 3)\n",
    "    \n",
    "    label_taskB = pd.DataFrame(data = lbp_features)\n",
    "    label_taskB['num_label'] = classes\n",
    "    label_taskB.to_csv(\"./dataset/label_taskB_lbp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ccedc61-4515-4e51-b896-950c2a81b52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file for Task B image data filtered with Canny filter already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./dataset/label_taskB_canny.csv'):\n",
    "    print('The csv file for Task B image data filtered with Canny filter already exists')\n",
    "else:\n",
    "    data_path = './dataset/image'\n",
    "    classes = create_classes(df)\n",
    "    canny_features = extract_canny(data_path, df, 3)\n",
    "    \n",
    "    label_taskB = pd.DataFrame(data = canny_features)\n",
    "    label_taskB['num_label'] = classes\n",
    "    label_taskB.to_csv(\"./dataset/label_taskB_canny.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "898d39e4-9a9c-4999-923a-1340c787d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 0.7  | test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "feature = 'hog'\n",
    "usingPCA = True\n",
    "\n",
    "if feature == 'hog':\n",
    "    # Doing classification with image HOG features\n",
    "    label_taskB = pd.read_csv(\"./dataset/label_taskB_hog.csv\")\n",
    "elif feature == 'lbp':\n",
    "    # Doing classification with image LBP features\n",
    "    label_taskB = pd.read_csv(\"./dataset/label_taskB_lbp.csv\")\n",
    "    usingPCA = True\n",
    "elif feature == 'canny':\n",
    "    # Doing classification with Canny filtered image data\n",
    "    label_taskB = pd.read_csv(\"./dataset/label_taskB_canny.csv\")\n",
    "    usingPCA = True\n",
    "    \n",
    "X = label_taskB.drop('num_label',axis=1) # All other features\n",
    "Y = label_taskB['num_label'] # numerical label/classes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 3) \n",
    "#test_size= should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split\n",
    "#everytime you run it without specifying random_state, you will get a different result, this is expected behavior\n",
    "#print (len(X_test), len(y_test))\n",
    "\n",
    "print('train set: {}  | test set: {}'.format(round(((len(y_train)*1.0)/len(X)),3),\n",
    "                                                       round((len(y_test)*1.0)/len(X),3)))\n",
    "# Doing image pre-processing with PCA\n",
    "if usingPCA == True:\n",
    "    k = 0.95\n",
    "    X_train, X_test = PCAPredict(X_train, X_test, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1e89b6d-3fe7-4cfa-ba66-213a9008ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNClassifier(X_train, y_train, X_test, k):\n",
    "    '''\n",
    "    Inputs\n",
    "        X_train: Training dataset;\n",
    "        y_train: Training labels;\n",
    "        X_test: Testing dataset;\n",
    "        k: Number of nearest neighbours to use.\n",
    "        \n",
    "    Return\n",
    "        Y_pred: Predicted labels from X_test using K-Nearest Neighbour.\n",
    "    '''\n",
    "\n",
    "    #Create KNN object with a K coefficient\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X_train, y_train) # Fit KNN model\n",
    "\n",
    "    Y_pred = neigh.predict(X_test)\n",
    "    \n",
    "    return Y_pred\n",
    "\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(X_train, y_train)\n",
    "# Y_pred = clf.predict(X_test)\n",
    "# throws error: setting an array element with a sequence\n",
    "# when getting X from dataframe, the resulting array is dtype object,\n",
    "# but when getting X directly from hog_features, resulting array is dtype float??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba3e312e-f29f-4218-a100-8bc8535e8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFClassifier(X_train, y_train, X_test, k):\n",
    "    '''\n",
    "    Inputs\n",
    "        X_train: Training dataset;\n",
    "        y_train: Training labels;\n",
    "        X_test: Testing dataset;\n",
    "        k: Number of trees in the forest.\n",
    "        \n",
    "    Return\n",
    "        Y_pred: Predicted labels from X_test using Random Forests.\n",
    "    '''\n",
    "    \n",
    "    clf=RandomForestClassifier(n_estimators=k)\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # prediction on test set\n",
    "    Y_pred=clf.predict(X_test)\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28f68f93-c85e-4955-bc93-8f1f6f4ab896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMClassifier(X_train, y_train, X_test):\n",
    "    '''\n",
    "    Inputs\n",
    "        X_train: Training dataset;\n",
    "        y_train: Training labels;\n",
    "        X_test: Testing dataset.\n",
    "        \n",
    "    Return\n",
    "        Y_pred: Predicted labels from X_test using SVM.\n",
    "    '''\n",
    "\n",
    "    #Create SCV object with a K coefficient\n",
    "    clf = svm.SVC(kernel='rbf', degree=3)\n",
    "    clf.fit(X_train, y_train) # Fit KNN model\n",
    "    Y_pred = clf.predict(X_test)\n",
    "\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "578c60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baggingClassifierML(X_train, y_train, X_test,k):\n",
    "\n",
    "    # Bagging takes Decision Tree as its base-estimator model by default.\n",
    "    bagmodel=BaggingClassifier(n_estimators=k,max_samples=0.5, max_features=4,random_state=1)\n",
    "    bagmodel.fit(X_train, y_train) # Fit KNN model\n",
    "\n",
    "\n",
    "    Y_pred = bagmodel.predict(X_test)\n",
    "    #print (Y_pred)\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0ad2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boostingClassifierML(X_train, y_train, X_test,k):\n",
    "    # AdaBoost takes Decision Tree as its base-estimator model by default.\n",
    "    boostmodel=AdaBoostClassifier(n_estimators=k)\n",
    "    boostmodel.fit(X_train, y_train,sample_weight=None) # Fit KNN model\n",
    "\n",
    "\n",
    "    Y_pred = boostmodel.predict(X_test)\n",
    "    #print (Y_pred)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec650809-e1d9-4061-abd5-1e2cb8fc9ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier score: 0.8155555555555556\n",
      "SVM classifier score: 0.8511111111111112\n",
      "Random Forest classifier score: 0.7677777777777778\n",
      "Bagging classifier score: 0.36333333333333334\n",
      "ADA Boosting classifier score: 0.5266666666666666\n"
     ]
    }
   ],
   "source": [
    "Y_pred_KNN = KNNClassifier(X_train, y_train, X_test, 4)\n",
    "score_KNN = metrics.accuracy_score(y_test, Y_pred_KNN)\n",
    "\n",
    "Y_pred_SVM = SVMClassifier(X_train, y_train, X_test)\n",
    "score_SVM = metrics.accuracy_score(y_test, Y_pred_SVM)\n",
    "\n",
    "Y_pred_RandomForest = RFClassifier(X_train, y_train, X_test, 100)\n",
    "score_RandomForest = metrics.accuracy_score(y_test, Y_pred_RandomForest)\n",
    "\n",
    "Y_pred_bagging = baggingClassifierML(X_train, y_train, X_test, 10)\n",
    "score_bagging = metrics.accuracy_score(y_test, Y_pred_bagging)\n",
    "\n",
    "Y_pred_boosting=boostingClassifierML(X_train, y_train, X_test, 10)\n",
    "score_boosting=metrics.accuracy_score(y_test, Y_pred_boosting)\n",
    "\n",
    "print('KNN classifier score:', score_KNN)\n",
    "print('SVM classifier score:', score_SVM)\n",
    "# print('Decision Tree classifier score:', score_Tree)\n",
    "print('Random Forest classifier score:', score_RandomForest)\n",
    "print('Bagging classifier score:', score_bagging)\n",
    "print('ADA Boosting classifier score:', score_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10977ee5-d61e-4bc5-bd02-895cadf3fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging classifier score: 0.3844444444444444\n",
      "ADA Boosting classifier score: 0.5522222222222222\n"
     ]
    }
   ],
   "source": [
    "Y_pred_bagging = baggingClassifierML(X_train, y_train, X_test, 15)\n",
    "score_bagging = metrics.accuracy_score(y_test, Y_pred_bagging)\n",
    "\n",
    "Y_pred_boosting=boostingClassifierML(X_train, y_train, X_test, 15)\n",
    "score_boosting=metrics.accuracy_score(y_test, Y_pred_boosting)\n",
    "\n",
    "print('Bagging classifier score:', score_bagging)\n",
    "print('ADA Boosting classifier score:', score_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95068ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
