{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d5a41a-c678-4948-9d24-9913ac575d3b",
   "metadata": {},
   "source": [
    "## 1.Import libraries\n",
    "The required libraries for this notebook are pandas, sklearn, numpy and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d6bc1c84-fd55-4585-9ed9-016e672474f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227b379-00da-4695-a41f-94036af9a743",
   "metadata": {},
   "source": [
    "## 2.1 Edit label.csv data\n",
    "Add column for binary label: 0 for no tumor, 1 for tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "974c3427-cae9-4502-9eaa-34df68ca6863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>glioma_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name             label\n",
       "0  IMAGE_0000.jpg  meningioma_tumor\n",
       "1  IMAGE_0001.jpg          no_tumor\n",
       "2  IMAGE_0002.jpg  meningioma_tumor\n",
       "3  IMAGE_0003.jpg      glioma_tumor\n",
       "4  IMAGE_0004.jpg  meningioma_tumor"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/label.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20953508-f9a5-4576-be11-2cfa0ce17b22",
   "metadata": {},
   "source": [
    "## 2.2 Add image data\n",
    "Add image data in the form of an array to the label data and save it in a new pickle file so it does not need to run everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5638825f-935e-494e-ab3d-a76adf331dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary(df):\n",
    "    binary = []\n",
    "    for label in df['label']:\n",
    "        if 'no_tumor' in label:\n",
    "            binary.append(0)\n",
    "        else:\n",
    "            binary.append(1)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd0ae277-c0aa-49d9-8043-632855552c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog(data_path, df):\n",
    "    hog_features = []\n",
    "    for filename in df['file_name']:\n",
    "        # use imread to load image from specified file name\n",
    "        im = imread(os.path.join(data_path, filename), as_gray = True)\n",
    "        # use resize the image to a 128 by 64 pixel image\n",
    "        resized_im = resize(im, (128, 64))\n",
    "        # Extract Histogram of Oriented Gradients (HOG) for the image\n",
    "        fd = hog(resized_im, orientations = 9, pixels_per_cell = (8, 8),\n",
    "                            cells_per_block = (2, 2), visualize = False, block_norm='L2-Hys')\n",
    "        hog_features.append(fd)\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "76af1bef-27d3-4798-b47f-df5e5d6469c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCAPredict(X_train, X_test, k):\n",
    "    '''\n",
    "    Inputs\n",
    "        X: dataset;\n",
    "        k: number of clusters.\n",
    "        \n",
    "    Return\n",
    "        X_reduced: The array of pixels (i.e. the image) after applying PCA to reduce its dimensions\n",
    "    '''\n",
    "\n",
    "    # the built-in function for PCA\n",
    "    pca = PCA(n_components=k)\n",
    "    \n",
    "    # fit the algorithm with dataset\n",
    "    pca.fit(X_train)\n",
    "    X_train_PCA = pca.transform(X_train)\n",
    "    X_test_PCA = pca.transform(X_test)\n",
    "    \n",
    "    return X_train_PCA, X_test_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c54138ea-8dd4-4380-9757-5c32394f5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_image(data_path, df):\n",
    "    image_data = []\n",
    "    for filename in df['file_name']:\n",
    "        # use imread to load image from specified file name\n",
    "        im = imread(os.path.join(data_path, filename), as_gray = True)\n",
    "        # use resize the image to a 128 by 64 pixel image\n",
    "        resized_im = resize(im, (128, 64))\n",
    "        # Extract Histogram of Oriented Gradients (HOG) for the image\n",
    "        flattened_image = resized_im.flatten()\n",
    "        image_data.append(flattened_image)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0801c7ec-7377-4824-aa93-e1514bc822c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pickle file for Task A with hog features data already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./dataset/label_taskA_hog.pkl'):\n",
    "    print('The pickle file for Task A with hog features data already exists')\n",
    "else:\n",
    "    data_path = './dataset/image'\n",
    "    binary = create_binary(df)\n",
    "    hog_features = extract_hog(data_path, df)\n",
    "    \n",
    "    label_taskA = pd.DataFrame(data = hog_features)\n",
    "    label_taskA['binary_label'] = binary\n",
    "    label_taskA.to_pickle(\"./dataset/label_taskA_hog.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e98245e6-507c-47c5-93a7-03f5f62ce077",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./dataset/label_taskA_flatten.pkl'):\n",
    "    print('The pickle file for Task A with flattened image data already exists')\n",
    "else:\n",
    "    data_path = './dataset/image'\n",
    "    binary = create_binary(df)\n",
    "    image_data = flatten_image(data_path, df)\n",
    "\n",
    "    label_taskA = pd.DataFrame(data = image_data)\n",
    "    label_taskA['binary_label'] = binary\n",
    "    label_taskA.to_pickle(\"./dataset/label_taskA_flatten.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "83b84b9c-30f6-4409-a5fb-af562452e83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pickle file with image data already exists\n"
     ]
    }
   ],
   "source": [
    "# if os.path.exists('./dataset/label_taskA.pkl'):\n",
    "#     print('The pickle file with image data already exists')\n",
    "# else:\n",
    "#     data_path = './dataset/image'\n",
    "#     # create an empty column to store image data\n",
    "#     # df['data'] = df['data'].astype(object)\n",
    "#     hog_features = []\n",
    "#     for filename in df['file_name']:\n",
    "#         # use imread to load image from specified file name\n",
    "#         im = imread(os.path.join(data_path, filename))\n",
    "#         # use resize the image to a 128 by 64 pixel image\n",
    "#         resized_im = resize(im, (128, 64))\n",
    "#         # Extract Histogram of Oriented Gradients (HOG) for the image\n",
    "#         fd = hog(resized_im, orientations = 9, pixels_per_cell = (8, 8),\n",
    "#                             cells_per_block = (2, 2), visualize = False, block_norm='L2-Hys')\n",
    "#         # find index/row number of image file name\n",
    "#         # idx = df.loc[df['file_name'] == filename].index[0]\n",
    "#         # save HOG information in 'data' column\n",
    "#         # df.loc[idx, 'data'] = [fd] \n",
    "#         # this resulted in an error: Must have equal len keys and value when setting with an ndarray\n",
    "#         hog_features.append(fd)\n",
    "        \n",
    "#     hog_features\n",
    "#     df.to_pickle(\"./dataset/label_taskA.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "71aecf51-46f7-4486-9610-4ed36fd79d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'flatten'\n",
    "usingPCA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "24addf05-9c85-4530-b58a-d2291de949de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature == 'hog':\n",
    "    # Doing classification with image HOG features\n",
    "    label_taskA = pd.read_pickle(\"./dataset/label_taskA_hog.pkl\")\n",
    "elif feature == 'flatten':\n",
    "    # Doing classification with flattened image data with PCA\n",
    "    label_taskA = pd.read_pickle(\"./dataset/label_taskA_flatten.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c7828b01-1c26-42f3-b750-2a08cbe6d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use np.unique to get all unique values in the list of labels\n",
    "# labels = np.unique(df_edited['label'])\n",
    "\n",
    "# # set up the matplotlib figure and axes, based on the number of labels\n",
    "# fig, axes = plt.subplots(1, len(labels))\n",
    "# fig.set_size_inches(15,4)\n",
    "# fig.tight_layout()\n",
    " \n",
    "# # make a plot for every label (equipment) type. The index method returns the \n",
    "# # index of the first item corresponding to its search string, label in this case\n",
    "# for ax, label in zip(axes, labels):\n",
    "#     idx = df_edited.loc[df_edited['label'] == label].index[0]\n",
    "#     ax.imshow(df_edited.loc[idx, 'data'])\n",
    "#     ax.axis('off')\n",
    "#     ax.set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5fd2cc0e-0e65-45eb-b3d8-f9c06b2251c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = label_taskA.drop('binary_label',axis=1) # All other features\n",
    "Y = label_taskA['binary_label'] # binary label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85420a2e-2180-439f-a413-89fd38e3dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 0.7  | test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 3) \n",
    "#test_size= should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split\n",
    "#everytime you run it without specifying random_state, you will get a different result, this is expected behavior\n",
    "#print (len(X_test), len(y_test))\n",
    "\n",
    "print('train set: {}  | test set: {}'.format(round(((len(y_train)*1.0)/len(X)),3),\n",
    "                                                       round((len(y_test)*1.0)/len(X),3)))\n",
    "if usingPCA == True:\n",
    "    k = 10\n",
    "    X_train, X_test = PCAPredict(X_train, X_test, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a4c7fc89-5895-4706-8103-3350b0290b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNClassifier(X_train, y_train, X_test,k):\n",
    "\n",
    "    #Create KNN object with a K coefficient\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X_train, y_train) # Fit KNN model\n",
    "\n",
    "\n",
    "    Y_pred = neigh.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(X_train, y_train)\n",
    "# Y_pred = clf.predict(X_test)\n",
    "# throws error: setting an array element with a sequence\n",
    "# when getting X from dataframe, the resulting array is dtype object,\n",
    "# but when getting X directly from hog_features, resulting array is dtype float??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1a3bc2d6-d098-466e-a5d0-d0c4e5741d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMClassifier(X_train, y_train, X_test):\n",
    "\n",
    "    #Create SCV object with a K coefficient\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train) # Fit KNN model\n",
    "    Y_pred = clf.predict(X_test)\n",
    "\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "001f8a7d-c7fe-42a7-a291-e583e5f9e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier score: 0.9166666666666666\n",
      "SVM classifier score: 0.8977777777777778\n"
     ]
    }
   ],
   "source": [
    "Y_pred_KNN = KNNClassifier(X_train, y_train, X_test, 4)\n",
    "score_KNN = metrics.accuracy_score(y_test, Y_pred_KNN)\n",
    "\n",
    "Y_pred_SVM = SVMClassifier(X_train, y_train, X_test)\n",
    "score_SVM = metrics.accuracy_score(y_test, Y_pred_SVM)\n",
    "\n",
    "print('KNN classifier score:', score_KNN)\n",
    "print('SVM classifier score:', score_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b14b5-5157-46d9-9ee7-f83dc13afdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
